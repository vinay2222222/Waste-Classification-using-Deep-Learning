# ğŸ—‘ï¸ Waste Classification Using Deep Learning  

Implementation of **RWC-Net** (DenseNet201 + MobileNetV2 hybrid) for **Recyclable Waste Classification**.  
"A Reliable and Robust Deep Learning Model for Effective Recyclable Waste Classification".  

This repo includes:  
âœ”ï¸ Dataset setup & preprocessing  
âœ”ï¸ **RWC-Net model (DenseNet201 + MobileNetV2 fusion)**  
âœ”ï¸ **5-fold cross-validation training pipeline**  

---

## ğŸ“‚ Repository Structure
```
RWC-Net-Waste-Classification/
â”‚â”€â”€ README.md
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ .gitignore
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ trashnet/                   # Dataset
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ RWCNet_Preprocessing.ipynb  # Colab notebook (dataset + preprocessing)
â”‚   â””â”€â”€ RWCNet_Training.ipynb       # Colab notebook (model training + CV)
â”‚
â””â”€â”€ src/
    â”œâ”€â”€ dataset.py                  # Dataset loading, preprocessing, augmentation
    â”œâ”€â”€ rwcnet_training.py          # RWC-Net + 5-fold CV training
```

---

## âš¡ Setup
Clone the repo and install dependencies:
```bash
git clone https://github.com/vinay2222222/Waste-Classification-using-Deep-Learning.git
cd Waste-Classification-using-Deep-Learning
pip install -r requirements.txt
```

---

## ğŸ“¥ Dataset
We use the [**TrashNet dataset**](https://github.com/garythung/trashnet), which contains **2527 images** across **6 waste categories**:  
- Cardboard  
- Glass  
- Metal  
- Paper  
- Plastic  
- Trash (Litter)  

Place the dataset inside:
```
data/trashnet/
```

Expected folder structure:
```
data/trashnet/
â”‚â”€â”€ cardboard/
â”‚â”€â”€ glass/
â”‚â”€â”€ metal/
â”‚â”€â”€ paper/
â”‚â”€â”€ plastic/
â”‚â”€â”€ trash/
```

---

## ğŸ› ï¸ Preprocessing
Defined in `src/dataset.py`:  
- **Resize**: `224 Ã— 224`  
- **Augmentation**:  
  - Random Horizontal Flip (p=0.5)  
  - Random Rotation (Â±30Â°)  
  - Random Crop (224Ã—224)  
- **Normalization**: ImageNet mean & std  
  - Mean = `[0.485, 0.456, 0.406]`  
  - Std = `[0.229, 0.224, 0.225]`  

---

## ğŸ¤– Model: RWC-Net
The **RWC-Net** model fuses two pretrained CNN backbones:  
- **DenseNet201**  
- **MobileNetV2**  

### Features:
- Extract embeddings from both backbones  
- Concatenate â†’ fully connected fusion layer  
- Auxiliary outputs from DenseNet and MobileNet  
- Final classifier with **LogSoftmax**  

---

## âš™ï¸ Training
We use **5-Fold Cross Validation** to ensure robustness.  

**Training setup** (`src/training.py`):  
- Optimizer: **Adam** (`lr = 1e-5`)  
- Loss: **CrossEntropyLoss** with weighted auxiliary losses  
  - Main loss: `1.0`  
  - Aux1: `0.5`  
  - Aux2: `0.25`  
- Evaluation: **Accuracy, Precision, Recall, F1-score**  

Run training:
```bash
python src/training.py
```

---

## ğŸ“’ Notebooks
- `Preprocessing.ipynb` â†’ Dataset setup + augmentations visualization  
- `Training.ipynb` â†’ Full training with 5-fold CV (Colab-ready)  

---

## ğŸ“Š Sample Training Logs
Example output during training (1 fold, 5 epochs):

â¡ï¸ After 5 folds, average accuracy is around **83â€“85%**, depending on augmentation randomness.  

---

## ğŸ“Œ Next Steps (Roadmap)

### ğŸ”¹ 1. Model Benchmarking (5 Models Compared)
- **ResNet50** (baseline)  
- **DenseNet121** (baseline)  
- **MobileNetV2** (baseline)  
- **EfficientNet-style** (baseline)  
- **RWC-Net (Proposed Model)**  

â¡ï¸ Compare Accuracy, Precision, Recall, F1-score across models.  

---

### ğŸ”¹ 2. Training & Evaluation Pipeline
- [ ] Automated training for all models  
- [ ] Detailed evaluation metrics  
- [ ] Visualization dashboard for results  
- [ ] Model checkpointing & saving  

---

### ğŸ”¹ 3. Deployment Options
**A. Gradio Web Interface**  
- Drag-and-drop waste image upload  
- Real-time classification with confidence scores  
- Clean UI with probabilities  
- Shareable public demo  

**B. REST API (Flask)**  
- JSON-based prediction endpoint  
- Health check endpoint  
- Easy system integration  

**C. Batch Processing**  
- Predict multiple images from a folder  
- Export CSV with predictions  
- Error handling for invalid images  


âœï¸ Maintainer: **Vinay A**  
